---
title: "sample_gtwpred_data"
output: pdf_document
date: "2024-08-16"
---
Wet and dry points were sampled from raw HAPET data in scripts 6-7. 
From there, the points are uploaded to GEE to extract predictor values.

This script samples from all (unoccluded) points, returning a subset of data for each of training and testing. 

# read libraries
```{r}
library(tidyverse)
library(sf)
library(here)

set.seed(123)

source(here("code", "helper_functions", "VIs.R"))
source(here("code", "helper_functions", "perform_kmeans.R"))
```

# set test years
```{r}
testyrs <- c("brood16", "2022", "2024")
trainyrs_fullppr <- c("2019", "2021", "2023")
nd_trainyrs <- c("pair16", "pair17", "brood17")
```

# load data
```{r}
states <- st_read(here("data", "boundaries", "states")) %>% 
  st_transform(4326)

plots <- st_read(here("data", "allPlots"))

# load ecoregion boundaries
ecoregion5 <- st_read(here("data", "boundaries", "reg5_eco_l3")) %>% st_transform(4326)
ecoregion7 <- st_read(here("data", "boundaries", "reg7_eco_l3")) %>% st_transform(4326)
ecoregion8 <- st_read(here("data", "boundaries", "reg8_eco_l3")) %>% st_transform(4326)
```

# read in GT points (2-wk composites)
Wrangling steps: 
  - rescale S2 L1C values
- drop values outside of -1 to 1
- convert flyvr_d to date
- calculate VIs
- get 1 nonnull plot_id col (drops some points, mostly dubious dry ones)

```{r}
# Define the folder path where shapefiles are located
folder_path_wet <- here("data", "gee_exports", "data_with_predictors", "PPR gtwPred-2wk", "wet_2wk_200")
folder_path_dry <- here("data", "gee_exports", "data_with_predictors", "PPR gtwPred-2wk", "dry_2wk")

# List all .shp files in the folder (ensure full path is returned)
shp_files_wet <- list.files(path = folder_path_wet, pattern = "\\.shp$", full.names = TRUE)
shp_files_dry <- list.files(path = folder_path_dry, pattern = "\\.shp$", full.names = TRUE)
shp_files <- c(shp_files_wet, shp_files_dry)

# Read each shapefile into a list of sf objects
shapefiles_list <- lapply(shp_files, function(file) {
  
  print(file)
  
  st_read(file, quiet = TRUE) %>%
    mutate(type = ifelse(grepl("wet", basename(file)), "wet", "dry")) %>% 
    st_set_crs(4326) %>% 
    return()
})

band_cols <- c("blue", "green", "red", "red_edge_1", "red_edge_2", "red_edge_3", "nir", "swir1", "swir2")

# Combine sf objects
all_samples <- do.call(bind_rows, shapefiles_list) %>% 
  dplyr::select(-b1) %>% 
  # rescale S2 L1C values
  mutate(across(all_of(band_cols),   
                ~ if_else(dataset %in% c("pair16", "brood16", "pair17", "brood17"), .x * 10000, .x))) %>%
  # drop values outside of -1 to 1
  filter(!if_any(all_of(band_cols), ~ .x < -1 | .x > 1)) %>% 
  # drop this 1 row
  filter(!(red==0 & nir==0)) %>% 
  # convert flyvr_d to date
  mutate(flyvr_d = as.Date(as.POSIXct(flyvr_d / 1000, origin = "1970-01-01", tz = "UTC"))) %>% 
  # keep only 1 plotid col
  mutate(plot_id = if_else(is.na(plot_id), Plot, plot_id)) %>% 
  select(-Plot) %>% 
  # Calculate VIs
  moreVIs() %>% 
  # drop rows with infinite values
  filter(!if_any(-geometry, is.infinite)) %>%
  # drop this too 
  filter(!is.na(NDRE)) 

# Some wet sampling occured outside of plot boundaries. Drop these. 
all_samples <- all_samples %>% filter(!is.na(plot_id)) 
```

# Add modified Level-III ecoregion
```{r}
# combine ecoregion layers
ecoregions <- bind_rows(ecoregion5, ecoregion7, ecoregion8) %>% 
  select(NA_L3NAME, NA_L2NAME)

# load ppr boundary
ppr <- st_read(here("data", "boundaries", "PPJV")) %>%
  st_transform(4326)

# get the ecoregions within the ppr
ppr_ecoregions <- st_intersection(ecoregions, ppr)

# modify ecoregion category, to consolidate (a region gets subsumed if <5 plots in it)
ppr_ecoregions2 <- ppr_ecoregions %>% 
  mutate(L3mod = case_when(
    NA_L3NAME %in% c("Northwestern Great Plains", "Middle Rockies", "Canadian Rockies", "Northwestern Glaciated Plains") ~ "Northwestern Plains",
    NA_L3NAME %in% c("North Central Hardwood Forests", "Northern Lakes and Forests") ~ "Northern Forests",
    NA_L3NAME %in% c("Lake Manitoba and Lake Agassiz Plain", "Northern Minnesota Wetlands") ~ "Lake Agassiz Plain",
    NA_L3NAME %in% c("Western Corn Belt Plains", "Driftless Area") ~ "Western Corn Belt Plains",
    T ~ NA_L3NAME
  ))

# add modified ecoregion to points
all_samples <- all_samples %>% st_join(ppr_ecoregions2) 
```

# Coordinate-based clustering of plots within each ecoregion
```{r}
######################

# Split by dataset and apply kmeans to each group (k=5)
clusters5 <- plots %>%
  st_centroid() %>% 
  st_join(ppr_ecoregions2, join=st_intersects) %>% 
  group_by(L3mod) %>% 
  group_split(L3mod) %>%
  lapply(perform_kmeans, k=5) 

# Do again but with more groups (a couple ecoregions are too big)
clusters12 <- plots %>%
  st_centroid() %>% 
  st_join(ppr_ecoregions2, join=st_intersects) %>% 
  group_by(L3mod) %>% 
  group_split(L3mod) %>%
  lapply(perform_kmeans, k=12) 

# Finally, do again for MT specifically
clustersMT <- plots %>%
  st_centroid() %>% 
  st_join(ppr_ecoregions2, join=st_intersects) %>% 
  st_join(states) %>% 
  filter(STUSPS=="MT") %>% 
  group_by(L3mod) %>% 
  group_split(L3mod) %>%
  lapply(perform_kmeans, k=6) 
```

# Pick test plots
This pulls about 14% of plots
```{r}
test_plot_ids_1 <- clusters5 %>% 
  bind_rows() %>% 
  filter((L3mod=="Western Corn Belt Plains" & cluster_id==5)
         | (L3mod=="Northern Forests" & cluster_id==4)
         | (L3mod=="Lake Agassiz Plain" & cluster_id==4))

test_plot_ids_2 <- clusters12 %>% 
  bind_rows() %>%
  filter((L3mod=="Aspen Parkland/Northern Glaciated Plains" & cluster_id==6)
         | (L3mod == "Northwestern Plains" & cluster_id==10))

test_plot_ids_3 <- clustersMT %>% 
  bind_rows() %>%
  filter(L3mod == "Northwestern Plains" & cluster_id==1)

test_plot_ids <- bind_rows(
    test_plot_ids_1, 
    test_plot_ids_2,
    test_plot_ids_3
  ) %>% 
  distinct(Plot) %>% 
  pull()
```

# Split all_samples into testing and training 
```{r}
# get test from novel areas and years
testing <- all_samples %>% 
  filter(dataset %in% testyrs | plot_id %in% test_plot_ids) 

# get train data
training <- all_samples %>% 
  filter(!(dataset %in% testyrs | plot_id %in% test_plot_ids)) 
```

# Add blocking variable to training set (2 folds per full year, 1 for '16-17)
```{r}
# Split by dataset and apply coordinate-based kmeans to each group 
training <- training %>%
  filter(dataset %in% trainyrs_fullppr) %>%
  group_split(dataset) %>%
  lapply(perform_kmeans, k=2) %>% 
  bind_rows() %>% 
  bind_rows(training %>% filter(!dataset %in% trainyrs_fullppr) %>% mutate(cluster_id=1)) %>% 
  ungroup() %>% 
  mutate(block = paste(cluster_id, "-", dataset)) 
```

# Export training/testing data
```{r}
write.table(test_plot_ids, here("data", "train_test_data", "test_plot_ids.txt"))

write_csv(training, here("data", "train_test_data", "unbalanced_training", "training_2wk_200pt.csv"), append=F)
write_csv(testing,  here("data", "train_test_data", "testing", "testing_2wk_200pt.csv"), append=F)

st_write(training, here("data", "train_test_data", "unbalanced_training", "training_2wk_200pt.shp"), append=F)
st_write(testing,  here("data", "train_test_data", "testing", "testing_2wk_200pt.shp"), append=F)
```
